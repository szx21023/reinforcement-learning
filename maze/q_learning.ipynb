{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Action:\n",
    "    def __init__(self, name: str, code: int, direction: list):\n",
    "        self.name = name\n",
    "        self.code = code\n",
    "        self.direction = direction\n",
    "        \n",
    "ACTIONS = [\n",
    "    Action('up', 0, [-1, 0]),\n",
    "    Action('down', 1, [1, 0]),\n",
    "    Action('left', 2, [0, -1]),\n",
    "    Action('right', 3, [0, 1])\n",
    "]\n",
    "\n",
    "class Maze:\n",
    "    def __init__(self, height: int, width: int, obstacle_ratio: float):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.obstacle_ratio = obstacle_ratio\n",
    "        self.array = [[h, w] for h in range(height) for w in range(width)]\n",
    "        self.table = np.zeros(shape=(height, width))\n",
    "    \n",
    "    def set_obstacle(self):\n",
    "        num = int((self.height*self.width)*self.obstacle_ratio)\n",
    "        self.obstacle = random.sample(self.array, num)\n",
    "        for pos in self.obstacle:\n",
    "            self.array.remove(pos)\n",
    "    \n",
    "    def set_reward_point(self):\n",
    "        self.reward_point = random.sample(self.array, 1)[0]\n",
    "        self.array.remove(self.reward_point)\n",
    "        \n",
    "    def set_reward_table(self):\n",
    "        self.reward_table = np.array([[-1 for w in range(self.width)] for h in range(self.height)])\n",
    "        for pos in self.obstacle:\n",
    "            self.reward_table[tuple(pos)] = -50\n",
    "        self.reward_table[tuple(self.reward_point)] = 50\n",
    "    \n",
    "    def get_obstacle(self) -> list:\n",
    "        return self.obstacle\n",
    "    \n",
    "    def get_reward_point(self) -> list:\n",
    "        return self.reward_point\n",
    "    \n",
    "    def get_reward_table(self) -> np.array:\n",
    "        return self.reward_table\n",
    "    \n",
    "    def out_of_boundary(self, h, w) -> bool:\n",
    "        return (h < 0) | (h >= self.height) | (w < 0) | (w >= self.width)\n",
    "    \n",
    "class Agent:\n",
    "    def __init__(self, position: list, actions: list, alpha: float=0.1, beta: float=0.2, gamma: float=0.2):\n",
    "        self.position = position\n",
    "        self.actions = actions\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def set_q_table(self, height: int, width: int):\n",
    "        self.q_table = np.zeros(shape=(height, width, len(self.actions)))\n",
    "    \n",
    "    def learn(self, pos: list, a: int, reward: int, new_pos: list=[]):\n",
    "        pos = tuple(pos)\n",
    "        new_pos = tuple(new_pos)\n",
    "        if new_pos == ():\n",
    "            self.q_table[pos][a] = self.q_table[pos][a] + self.alpha * \\\n",
    "            (reward - self.q_table[pos][a])\n",
    "        else:\n",
    "            self.q_table[pos][a] = self.q_table[pos][a] + self.alpha * \\\n",
    "            (reward + self.beta * max(self.q_table[new_pos]) - self.q_table[pos][a])\n",
    "\n",
    "    def get_next_step(self, pos: list) -> int:\n",
    "        pos = tuple(pos)\n",
    "        if self.gamma > random.random():\n",
    "            return random.choice(self.actions).code\n",
    "        else:\n",
    "            return np.argmax(agent.q_table[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e205a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = Maze(height=10, width=10, obstacle_ratio=0.2)\n",
    "maze.set_obstacle()\n",
    "maze.set_reward_point()\n",
    "maze.set_reward_table() \n",
    "reward_table = maze.get_reward_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb5ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent([0, 0], ACTIONS)\n",
    "agent.set_q_table(*reward_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    agent.position = [0, 0]\n",
    "    while True:\n",
    "        a_index = agent.get_next_step(agent.position)\n",
    "        direction = ACTIONS[a_index].direction\n",
    "        new_position = [agent.position[0] + direction[0], agent.position[1] + direction[1]]\n",
    "        if maze.out_of_boundary(*new_position):\n",
    "            reward = -50\n",
    "            agent.learn(agent.position, a_index, reward)\n",
    "            print('game over!')\n",
    "            break\n",
    "\n",
    "        reward = reward_table[tuple(new_position)]\n",
    "        print(agent.position, a_index, reward)\n",
    "        agent.learn(agent.position, a_index, reward, new_position)\n",
    "        agent.position = new_position\n",
    "        if maze.reward_point == new_position:\n",
    "            print('get reward!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02713460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_actions_of_all_states(q_table):\n",
    "    height, width = q_table.shape[:2]\n",
    "    l = []\n",
    "    for h in range(height):\n",
    "        tmp_l = []\n",
    "        for w in range(width):\n",
    "            tmp_l.append(np.argmax(q_table[h, w, :]))\n",
    "        l.append(tmp_l)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = best_actions_of_all_states(agent.q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ba914",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd47fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442793e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
